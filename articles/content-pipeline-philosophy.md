---
title: "コンテンツパイプラインという思想 -- 日常から記事が生まれる仕組みの設計"
emoji: "🌱"
type: "idea"
topics: ["obsidian", "ai", "pkm", "claudecode", "writing"]
published: false
published_at: "2026-02-15 12:30"
publication_name: "correlate_dev"
slug: "content-pipeline-philosophy"
---

## はじめに: メモは溜まるのに記事にならない

Obsidianに500以上のファイルがある。セッションログ、エラー記録、設計判断メモ。どれも価値のある情報のはず。なのに、技術記事の公開は月0本――そんな状態が半年以上続いていました。

「素材はあるのに記事にならない」。この現象に心当たりのある方は少なくないのではないでしょうか。

PKM（パーソナルナレッジマネジメント）ツールの普及により、メモを取る行為そのものは簡単になりました。Obsidian、Notion、Logseq。ツールは洗練され、テンプレートもプラグインも充実している。それでもアウトプットが増えないのは、「メモから記事への変換」に構造的な断絶があるから。

本記事では、その断絶を埋めるために「コンテンツパイプライン」という設計思想を提案します。ソフトウェア工学のCI/CDに着想を得て、PKMの知見を記事に変換する仕組みをどう設計するか。「どう自動化するか」ではなく「なぜ仕組みを設計するのか」――そこを語る記事です。

:::message
本記事は設計思想（Why）を語るidea記事です。実装の具体的な手順（How）は、姉妹記事の「[Claude Code × Agent Teamsで1日5本のZenn記事を書いた方法](https://zenn.dev/correlate_dev/articles/ai-content-pipeline)」で詳しく解説しています。
:::

## 1. 3つの先行思想を整理する

コンテンツパイプラインの設計思想は、ゼロから生まれたものではありません。先行する3つの思想から多くを借りている。それぞれの強みと弱点を整理するところから始めましょう。

### Digital Garden: 育てるメタファー

Andy Matuschakは「Work with the garage door up（ガレージのドアを開けて作業する）」と表現しました。完成品ではなく、思考のプロセスを公開すること自体に価値がある、という考え方です。

Maggie Appletonは、この思想をさらに洗練させた人物。彼女のDigital Gardenモデルでは、ノートが3段階で「育つ」と捉える。

- **Seedlings（種）**: 生まれたてのアイデア。未整理で断片的
- **Budding（芽）**: ある程度の構造を持ち始めたノート
- **Evergreens（常緑樹）**: 十分に練られ、独立して読める知識

「庭」のメタファーが意味するのは、完璧を目指さなくていいということ。不完全でも公開し、時間をかけて育てればいい。書くハードルを劇的に下げた功績は大きい。

ただし弱点もあります。「記事」としての完成度や読者体験は二の次になりがち。SEOやプラットフォームでの発見可能性も考慮されていません。庭は美しいけれど、「庭の外」にいる読者には届きにくいのが現実でしょう。

### Second Brain: 知識を外部化する

Tiago Forteが提唱した「Building a Second Brain」は、PKMを4つのステップに体系化したフレームワーク。CODEと呼ばれている。

1. Capture（収集）: 気になった情報を保存する
2. Organize（整理）: PARA（Projects / Areas / Resources / Archives）で分類
3. Distill（蒸留）: 本質を抽出する
4. Express（表現）: アウトプットとして世に出す

体系が明確で、再現性が高い。「何をどの順番でやればいいか」が分かる安心感は、多くの実践者に支持されている。

しかし問題がある。4つのステップのうち、最も曖昧なのが最後の「Express」です。Capture、Organize、Distillまでは手順化しやすい。メモを取り、フォルダに分け、要点を絞る。ところが「要点を絞ったメモを、読者のために書き直す」ステップには、具体的なガイドがほとんど用意されていない。

結果として、多くのSecond Brain実践者がDistillの段階で止まる。整理されたノートは増えていく。でも記事にはならない。

### Zettelkasten: 原子的なメモを繋げる

社会学者のNiklas Luhmannが実践した手法で、1ノート1アイデアの原則が核心です。メモを「原子（アトミック）」に保つことで再利用性を最大化し、メモ同士のリンクから新しい着想が生まれるという思想。

Luhmannはこの方法で70冊以上の著作と400本以上の論文を生み出しました。メモの蓄積が新しいアイデアへと自動的に接続される仕組みの威力は、歴史が証明済みです。

一方で、Zettelkastenは「内省」に閉じがちな面がある。メモ同士のリンクは豊かになるが、そこから外部向けの「記事」や「作品」を生み出すプロセスは体系化されていません。Luhmann自身は天才的な執筆者だったから機能したものの、仕組みとして「出力」までを保証するものではない。

## 2. 共通する「Express問題」

3つの思想を並べてみると、共通する弱点が見えてきます。

| 思想 | Capture | Organize | Distill | Express |
|:--|:--|:--|:--|:--|
| Digital Garden | -- | -- | -- | 「育つ」に任せる |
| Second Brain | Capture | Organize | Distill | 曖昧 |
| Zettelkasten | 1ノート1概念 | リンク構造 | 蒸留不要（原子的） | 仕組みなし |

入力から蓄積・整理までは優れている。しかし「メモを外部向けの成果物に変換する」ステップが、いずれの思想でも構造化されていません。これを本記事では **「Express問題」** と呼ぶことにします。

Express問題が起きる理由は3つあると考えている。

1つ目は完璧主義の壁。メモは自分向けだから気楽に書ける。しかし「記事」となった瞬間、読者の目を意識して手が止まる。Digital Gardenは「不完全でもいい」と言うけれど、ZennやQiitaに投稿するとなれば話は別でしょう。

2つ目は文脈の再構築コスト。メモは書いた時点の文脈を前提にしている。1ヶ月後に読み返すと、「これ何の話だったっけ」からスタートすることもある。自分のメモなのに、記事化するためには文脈を一から組み立て直す必要がある。

3つ目は読者視点への転換。自分が理解していることを、初見の読者に伝わる形に書き換えるのは、メモを取ることとはまったく別のスキル。この転換コストが高すぎて、「まあ、また今度でいいか」と先送りにしてしまう。

つまりExpress問題とは、意志力や時間管理の問題ではない。「メモから記事への変換パイプラインが存在しない」という構造的な問題なのです。

## 3. パイプラインという設計思想

### ソフトウェア工学からの借用

ソフトウェア開発には、CI/CD（継続的インテグレーション/継続的デリバリー）という概念がある。開発者がコードを書いてコミットすると、自動テスト → ビルド → デプロイが順番に実行される。人間が毎回手動でテストし、手動でサーバーにアップロードしていた時代とは生産性が桁違いだ。

ここで重要なのは何か。CI/CDは「完全自動化」ではないという点です。コードを書くのは人間の仕事で、自動化されているのは「コードから本番環境への変換プロセス」。入力は人間、変換は仕組み。

コンテンツ制作にも同じ構造を適用できるのではないか。日々の開発で得た知見（入力）を、仕組み（パイプライン）によって記事（成果物）に変換する。この発想がコンテンツパイプラインの出発点だった。

### 6フェーズの設計

実際に運用しているパイプラインは、6つのフェーズで構成されています。

```
Phase 1: 候補発見    ← 日常の「気づき」をキャプチャ
Phase 2: Deep Research ← 必須ゲート（省略禁止）
Phase 3: 執筆       ← AI Agent活用
Phase 4: DAレビュー  ← 品質ゲート
Phase 5: 公開       ← Zenn / Note
Phase 6: フィードバック → Phase 1に戻る
```

各フェーズの間に「ゲート」が設定されている点がポイント。特にPhase 2のDeep Research（競合調査・参考資料収集）は、体験型の記事であっても省略禁止としている。類似記事を調べずに書くと車輪の再発明になるリスクがあり、差別化ポイントはリサーチからしか見えてこないためだ。

Phase 6のフィードバックがPhase 1に戻るのは何を意味するか。パイプラインが閉じたループを形成していることを示している。リサーチ中に次の記事ネタが見つかる。公開後の反応が新しい知見になる。記事を書く行為自体が次の記事の素材を生む。この循環構造こそが、「ネタ切れ」を構造的に防ぐ仕組みです。

### Gardener x Architect のハイブリッド

Jeffrey Webberは「Knowledge Pipelines -- Are They Too Complex?」というエッセイで、パイプラインの過剰設計を批判した。学びを義務に変えてしまう危険性がある、と。

この指摘は正しい。PKMの世界には「Gardener（庭師）」型と「Architect（建築家）」型という2つのアプローチがあり、パイプラインは明らかにArchitect寄り。構造を作りすぎると、メモを取ること自体が苦痛になりかねない。

だからこそ、「仕組みは厳密に、入力は自由に」というハイブリッドを意識している。

具体的にはどういうことか。Phase 1（候補発見）の入力は徹底的に自由にする。作業中に「これは記事になりそうだ」と感じたら、`#content-candidate` タグとタイトル案を1行メモするだけ。所要時間は0.5秒。完璧なメモを書く必要はないし、フォーマットも問わない。Zettelkastenでいう「フリートノート」に近い軽さだ。

一方、Phase 2以降は構造化されている。リサーチのテンプレート、レビューの観点、公開のチェックリスト。これらは「仕組み」として固定されているから、毎回ゼロから考える必要がない。

入口はGardener的な自由さ、出口はArchitect的な構造。この組み合わせが、パイプラインの複雑さを感じさせずに品質を維持する鍵だと考えています。

## 4. なぜ「日常から」が重要なのか

### 開発作業 = コンテンツの原料

エンジニアは、毎日コンテンツの種を生み出している。

ライブラリのバージョンアップで踏んだ落とし穴。設計判断で迷った末に選んだアーキテクチャ。チームの開発フローを改善した施策。どれもが、同じ課題を抱える誰かにとって価値ある情報だ。

問題は何か。「気づかないこと」と「変換しないこと」の2つ。日常の作業に埋もれた知見は、意識的にキャプチャしなければ揮発する。そしてキャプチャしたとしても、Express問題が待ち構えている。

### 気づきを逃さない仕組み

パイプラインのPhase 1で`#content-candidate`タグを使う理由は、「気づきの揮発」を防ぐため。

作業中に「おっ、これは」と思った瞬間にタグを付ける。判断基準は直感で構いません。あとから候補リストを見返して、実際に記事化するかどうかを判断すればいい。大事なのは、気づきの瞬間を逃さないこと。

この考え方はAndy Matuschakの「Evergreen Notes」に通じる。完成品を目指すのではなく、思考の断片を保存する。ただしDigital Gardenと違うのは、保存した断片をパイプラインに載せて「完成品」へ変換するプロセスが用意されている点。ここがGardenとPipelineの決定的な差だ。

### 記事が次の記事を生む循環構造

パイプラインを運用して実感したのは、「記事を書く行為自体が、次の記事のネタを生む」ということ。

Deep Researchの過程で見つかる関連トピック。執筆中に言語化される新しい気づき。公開後の読者フィードバック。Phase 6（フィードバック）がPhase 1（候補発見）に戻る循環は、理論ではなく実体験から設計したものだ。

実際に、本記事のリサーチ中にも5つの新しい記事候補が見つかった。「Gardener vs Architectの第三の道」「Andy Matuschakの思想を実践してみた」など。パイプラインの出力が次の入力になる。ネタ切れは、仕組みの問題であって創造力の問題ではなかったのだと今は思う。

## 5. 品質ゲートという安全装置

### Deep Research: 省略禁止の理由

パイプラインに「必須ゲート」を設けている理由は、品質の底上げだけではない。差別化のためでもある。

体験型の記事であっても、Deep Researchは省略禁止にしている。競合記事を調べ、参考資料を収集し、キーワードを分析する。このプロセスを経ることで、「自分の体験の、どこに独自の価値があるか」が初めて見えてくる。

実際に、このパイプラインを使って1日5本のZenn記事を書いた実績がある（詳細は姉妹記事「[Claude Code × Agent Teamsで1日5本のZenn記事を書いた方法](https://zenn.dev/correlate_dev/articles/ai-content-pipeline)」参照）。理論だけでなく、運用実績がこの設計思想を裏付けている。

本記事のリサーチでも、Zenn上に「コンテンツパイプライン」を思想として語る記事がほぼ存在しないことが判明した。HowTo記事（どう自動化するか）や体験記事（何本書いたか）は豊富にある。しかし「なぜこの仕組みを設計するのか」という設計論はブルーオーシャンだった。この発見がなければ、本記事の方向性は大きく異なっていたでしょう。

### DAレビュー: AIが書いたものをAIが批判する

Googleの検索品質評価ガイドライン（2025年1月更新）では、AIで大量生成されたコンテンツが「努力なし・独自性なし・付加価値なし」の場合に最低品質（Lowest Quality）と評価されると明記されている[^1]。AIを活用するなら、品質管理の仕組みは不可欠だ。

パイプラインのPhase 4では、DA（デビルズアドボケイト）と呼ぶ批判的レビュー工程を設けている。事実確認、論理構成、文体チェックの3層で検証する仕組みだ。

ポイントは、DAレビューを1回で終わらせないこと。R1（初回指摘）→ R2（修正確認）→ R3（最終チェック）と多段で回すことで、見落としを段階的に潰していく。以前の運用では、5本の記事で太字マーカーが84箇所使われていた問題や、統計データの誤引用がR1で検出されたことがあった。こうした問題は、1回のレビューでは発見しきれない。

「AIで書いたものをAIが批判する」のは矛盾に聞こえるかもしれない。しかし、書く役割と批判する役割を分離することで、忖度のないレビューが可能になる。人間のセルフレビューでは、自分の文章に対する「あばたもえくぼ」バイアスが避けられない。役割分離は、品質管理の基本的な設計原則だ。

## 6. Learn in Public / Build in Public との接続

Andy Matuschakの「ガレージのドアを開けて作業する」という考え方は、近年の「Build in Public」ムーブメントと深く共鳴している。Build in Publicとは、製品やプロジェクトの開発過程を公開しながら進めるムーブメント。成功も失敗も透明に共有することで、コミュニティからのフィードバックを得て学びを加速させる。

コンテンツパイプラインは、この「公開する姿勢」を仕組みとして制度化したもの。そう位置づけることができる。

Digital Gardenが「公開の意志」に依存するのに対し、パイプラインは「公開までの変換プロセス」を設計する。意志の強さに頼らず、仕組みの力で「日常の知見が公開コンテンツに変わる」状態をつくる。Maggie Appletonの成長段階モデル（Seedlings → Budding → Evergreens）を、Phase 1（候補）→ Phase 3（ドラフト）→ Phase 5（公開）という具体的な工程に落とし込んだ形とも言えるだろう。

個人の知識がパイプラインを通じて公開され、読者のフィードバックが次の知識になる。この循環が回り始めると、個人のPKMが「公共財」へと接続されていく。エンジニアの日常的な作業ログが、同じ問題で悩む誰かの助けになるかもしれない。そう考えると、パイプラインを設計する行為は、自分のためだけでなく、コミュニティへの貢献でもあるのではないでしょうか。

## まとめ: メモは資産、パイプラインは投資

本記事で提案した「コンテンツパイプライン」の設計思想を振り返る。

第一に、PKMの「Express問題」への解答。Digital Garden、Second Brain、Zettelkastenの3つの先行思想は、いずれも入力から整理までは優れているが、「記事への変換」が構造化されていなかった。パイプラインは、その変換プロセスそのものを設計する試みだ。

第二に、CI/CDの発想をコンテンツに適用。ソフトウェア開発のパイプラインと同じく、入力は人間、変換は仕組み。6フェーズ + 品質ゲートの設計で、品質を維持しながらアウトプットを増やす。

第三に、Gardener x Architect のハイブリッド。入口はGardener的な自由さ（タグ1つで候補登録）、出口はArchitect的な構造（必須ゲート + DAレビュー）。仕組みは厳密に、入力は自由に。

第四に、記事が記事を生む循環構造。パイプラインの出力が次の入力になる。ネタ切れは創造力の問題ではなく、仕組みの問題だった。

仕組みの初期設計には、それなりの時間がかかる。テンプレートの整備、ゲート条件の定義、レビュープロセスの構築。しかし一度つくれば、あとは日常の開発作業から記事が「流れ出す」ようになる。メモは資産であり、パイプラインはその資産を運用するための投資だ。

「AIで書く」のではなく、「知識がAIを通じて記事になる」。その仕組みを設計することが、AI時代のエンジニアにとって最も価値ある投資の一つではないでしょうか。

:::message
本記事の実装詳細（Agent Teamsの構成、テンプレート、DAレビューの手順）は「[Claude Code × Agent Teamsで1日5本のZenn記事を書いた方法](https://zenn.dev/correlate_dev/articles/ai-content-pipeline)」で解説しています。「Why」を理解した上で「How」に進みたい方は、ぜひそちらもご覧ください。
:::

## 参考

### 思想的基盤

https://notes.andymatuschak.org/Work_with_the_garage_door_up

https://notes.andymatuschak.org/Evergreen_notes

https://maggieappleton.com/evergreens

https://maggieappleton.com/garden-history

https://buildingasecondbrain.com/

https://zettelkasten.de/atomicity/guide/

### パイプライン設計に関する議論

https://medium.com/@jeffreywebber_/knowledge-pipelines-are-they-too-complex-bbf4eba1b007

https://notelab.hypotheses.org/2336

### AI x コンテンツ生成トレンド

https://www.suzukikenichi.com/blog/ai-generated-content-references-in-the-search-quality-evaluator-guidelines-updated-on-january-2025/

### 関連記事（著者）

https://zenn.dev/correlate_dev/articles/ai-content-pipeline

https://zenn.dev/correlate_dev/articles/obsidian-claude-code

[^1]: Google検索品質評価ガイドライン（2025年1月更新）では、AIで大量生成されたコンテンツが「努力なし・独自性なし・付加価値なし」の場合に最低品質（Lowest Quality）と評価されると明記されている。
