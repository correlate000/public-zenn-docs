---
title: "Celery Ã— Redisã§éåŒæœŸã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼å®Ÿè£… â€” ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ãƒ»ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ãƒ»ç›£è¦–ã‚’å®Œå…¨æ”»ç•¥"
emoji: "ğŸŒ¸"
type: "tech"
topics: ["python", "celery", "redis", "fastapi", "asyncprocessing"]
published: false
publication_name: "correlate_dev"
---

## ã¯ã˜ã‚ã«

Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’æœ¬ç•ªé‹ç”¨ã—ã¦ã„ã‚‹ã¨ã€ã€Œãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™å‰ã«é‡ã„å‡¦ç†ãŒèµ°ã‚‹ã€ã¨ã„ã†å•é¡Œã«å¿…ãšç›´é¢ã—ã¾ã™ã€‚ãƒ¡ãƒ¼ãƒ«é€ä¿¡ãƒ»PDFç”Ÿæˆãƒ»å¤–éƒ¨APIå‘¼ã³å‡ºã—ãƒ»æ©Ÿæ¢°å­¦ç¿’æ¨è«–ãªã©ã€æ•°ç§’ã€œæ•°åç§’ã‹ã‹ã‚‹å‡¦ç†ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¹ãƒ¬ãƒƒãƒ‰ã§åŒæœŸå®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ä½“é¨“ã®æ‚ªåŒ–ã ã‘ã§ãªãã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚„ã‚µãƒ¼ãƒãƒ¼ãƒªã‚½ãƒ¼ã‚¹ã®æ¯æ¸‡ã«ã¤ãªãŒã‚Šã¾ã™ã€‚

è§£æ±ºç­–ãŒéåŒæœŸã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã§ã™ã€‚ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¯å³åº§ã«ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã—ã€é‡ã„å‡¦ç†ã¯ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ãŒæ‹…ã†è¨­è¨ˆã«ã—ã¾ã™ã€‚

Python ã‚¨ã‚³ã‚·ã‚¹ãƒ†ãƒ ã§ã“ã®å½¹å‰²ã‚’æ‹…ã†ä»£è¡¨æ ¼ãŒ Celery ã§ã™ã€‚2009å¹´ã«ç™»å ´ã—ãŸ Celery ã¯2025å¹´ç¾åœ¨ã‚‚æ´»ç™ºã«é–‹ç™ºãŒç¶šã„ã¦ãŠã‚Šã€ãƒãƒ¼ã‚¸ãƒ§ãƒ³5.5ç³»ã§ã¯å®‰å®šæ€§ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã‚‚ã«é«˜ã„æ°´æº–ã‚’ç¶­æŒã—ã¦ã„ã¾ã™ã€‚æœ¬è¨˜äº‹ã§ã¯ Celery ã¨ Redis ã‚’çµ„ã¿åˆã‚ã›ãŸå®Ÿè£…ã‚’ã€ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‹ã‚‰æœ¬ç•ªé‹ç”¨ã¾ã§ä½“ç³»çš„ã«è§£èª¬ã—ã¾ã™ã€‚

## ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

Celery ãŒæ‰±ã†æ¦‚å¿µã¯4ã¤ã§ã™ã€‚

| ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ | å½¹å‰² | å…¸å‹çš„ãªå®Ÿè£… |
|---|---|---|
| Producer | ã‚¿ã‚¹ã‚¯ã‚’ç”Ÿæˆã—ã¦ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€ | FastAPI / Django |
| Broker | ã‚¿ã‚¹ã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸€æ™‚ä¿å­˜ãƒ»é…é€ã™ã‚‹ | Redis / RabbitMQ |
| Worker | ã‚­ãƒ¥ãƒ¼ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’å–ã‚Šå‡ºã—ã¦å®Ÿè¡Œã™ã‚‹ | Celery Worker ãƒ—ãƒ­ã‚»ã‚¹ |
| Backend | ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œçµæœã‚’ä¿å­˜ã™ã‚‹ | Redis / PostgreSQL |

å‡¦ç†ã®æµã‚Œã‚’å›³ç¤ºã—ã¾ã™ã€‚

```mermaid
sequenceDiagram
    participant C as Client
    participant A as FastAPI (Producer)
    participant B as Redis (Broker)
    participant W as Celery Worker
    participant R as Redis (Backend)

    C->>A: POST /send-email
    A->>B: ã‚¿ã‚¹ã‚¯ã‚’ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚ºã—ã¦ enqueue
    A-->>C: 202 Accepted + task_id
    B->>W: ã‚¿ã‚¹ã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ deliver
    W->>W: ã‚¿ã‚¹ã‚¯å®Ÿè¡Œï¼ˆãƒ¡ãƒ¼ãƒ«é€ä¿¡ãªã©ï¼‰
    W->>R: å®Ÿè¡Œçµæœã‚’ä¿å­˜
    C->>A: GET /task/{task_id}/status
    A->>R: çµæœã‚’ç…§ä¼š
    A-->>C: {"state": "SUCCESS", "result": ...}
```

Broker ã¨ Backend ã®é•ã„ã¯æ··åŒã—ã‚„ã™ã„ãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚Broker ã¯ã‚¿ã‚¹ã‚¯ã®ã€Œé…é€ã€ã«ç‰¹åŒ–ã—ãŸä¸€æ–¹é€šè¡Œã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚­ãƒ¥ãƒ¼ã§ã™ã€‚Backend ã¯ã€Œçµæœã®æ°¸ç¶šåŒ–ã€ã‚’æ‹…ã„ã€Producer ãŒãƒãƒ¼ãƒªãƒ³ã‚°ã§çµæœã‚’å–å¾—ã™ã‚‹ãŸã‚ã«ä½¿ã„ã¾ã™ã€‚ã©ã¡ã‚‰ã‚‚ Redis ã‚’ä½¿ã†ã“ã¨ã¯ã§ãã¾ã™ãŒã€ç”¨é€”ãŒç•°ãªã‚‹ãŸã‚æ¦‚å¿µä¸Šã¯åˆ†é›¢ã—ã¦è€ƒãˆã¾ã™ã€‚

## Celery vs Cloud Tasks â€” ä½¿ã„åˆ†ã‘ã®åŸºæº–

ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰ãªã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼ã¨ã—ã¦ Google Cloud Tasks ã‚‚é¸æŠè‚¢ã«ãªã‚Šã¾ã™ã€‚åˆ¤æ–­åŸºæº–ã‚’æ•´ç†ã—ã¾ã™ã€‚

```mermaid
flowchart TD
    Start([ã‚¿ã‚¹ã‚¯ã‚­ãƒ¥ãƒ¼é¸å®š]) --> Q1{GCPã«å®Œå…¨ä¾å­˜<br/>ã—ã¦ã‚ˆã„ã‹ï¼Ÿ}
    Q1 -->|Yes| Q2{ã‚¿ã‚¹ã‚¯æ•°ãŒæœˆ<br/>100ä¸‡ä»¥ä¸‹ï¼Ÿ}
    Q1 -->|No / ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰| Celery[Celery + Redis]
    Q2 -->|Yes| Q3{ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°<br/>ãŒä¸»ãªç”¨é€”ï¼Ÿ}
    Q2 -->|No / å¤§é‡ãƒãƒ¼ã‚¹ãƒˆ| Celery
    Q3 -->|Yes| CloudScheduler[Cloud Scheduler]
    Q3 -->|No| CloudTasks[Cloud Tasks]
    CloudTasks --> Note1[æœˆ100ä¸‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§ç„¡æ–™<br/>ä»¥é™ $0.4/ç™¾ä¸‡]
    Celery --> Note2[ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç†ãŒå¿…è¦ã ãŒ<br/>é«˜åº¦ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ãŒå¯èƒ½]
```

| è¦³ç‚¹ | Celery + Redis | Cloud Tasks |
|---|---|---|
| ã‚¤ãƒ³ãƒ•ãƒ©ç®¡ç† | Redisãƒ»Worker ã®é‹ç”¨ãŒå¿…è¦ | ãƒ•ãƒ«ãƒãƒãƒ¼ã‚¸ãƒ‰ |
| ã‚³ã‚¹ãƒˆï¼ˆå°è¦æ¨¡ï¼‰ | Redis ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹è²»ç”¨ãŒå›ºå®šã§ã‹ã‹ã‚‹ | æœˆ100ä¸‡ãƒªã‚¯ã‚¨ã‚¹ãƒˆã¾ã§ç„¡æ–™ |
| ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ | chainãƒ»groupãƒ»chord ã§è¤‡é›‘ãªä¾å­˜é–¢ä¿‚ã‚’çµ„ã‚ã‚‹ | å˜ç´”ãªéåŒæœŸå®Ÿè¡Œã®ã¿ |
| ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚° | Celery Beat | Cloud Scheduler ã§ä»£æ›¿ |
| ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™º | Docker Compose ã§å®Œçµ | ã‚¨ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚¿ãŒå¿…è¦ |
| é©åˆã‚·ãƒ¼ãƒ³ | è¤‡é›‘ãªãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ»ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»æ—¢å­˜ Redis æ´»ç”¨ | GCP ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ»ã‚·ãƒ³ãƒ—ãƒ«ãªé…å»¶å®Ÿè¡Œ |

è¤‡é›‘ãªã‚¿ã‚¹ã‚¯ä¾å­˜é–¢ä¿‚ã‚„æ—¢å­˜ã® Redis ã‚¤ãƒ³ãƒ•ãƒ©ãŒã‚ã‚‹å ´åˆã¯ Celery ãŒå„ªä½ã§ã™ã€‚GCP ã§å°è¦æ¨¡ãªã‚·ãƒ³ãƒ—ãƒ«éåŒæœŸå‡¦ç†ã§ã‚ã‚Œã° Cloud Tasks ã®æ–¹ãŒã‚³ã‚¹ãƒˆã¨é‹ç”¨è² è·ã®é¢ã§æœ‰åˆ©ã§ã™ã€‚

## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

### ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install celery[redis] redis fastapi uvicorn
# ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ç”¨
pip install flower
# ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°ç”¨ï¼ˆdjangoä»¥å¤–ã§ã‚‚å‹•ä½œï¼‰
pip install celery[beat]
```

### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

```
myapp/
â”œâ”€â”€ celery_app.py      # Celery ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã¨è¨­å®š
â”œâ”€â”€ tasks/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ email_tasks.py
â”‚   â””â”€â”€ report_tasks.py
â”œâ”€â”€ main.py            # FastAPI ã‚¢ãƒ—ãƒª
â””â”€â”€ docker-compose.yml
```

### Celery ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®åˆæœŸåŒ–

```python
# celery_app.py
from celery import Celery
import os

REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:6379/0")

app = Celery(
    "myapp",
    broker=REDIS_URL,
    backend=REDIS_URL,
    include=["tasks.email_tasks", "tasks.report_tasks"],
)

app.conf.update(
    # ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶è¨­å®š
    task_serializer="json",
    accept_content=["json"],
    result_serializer="json",
    timezone="Asia/Tokyo",
    enable_utc=True,
    # çµæœã®ä¿æŒæœŸé–“ï¼ˆ1æ—¥ï¼‰
    result_expires=86400,
    # ã‚¿ã‚¹ã‚¯ãŒé‡è¤‡å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã®è­¦å‘Šã‚’æŠ‘åˆ¶ã—ãªã„
    task_track_started=True,
    # ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒä¸€åº¦ã«å–å¾—ã™ã‚‹ã‚¿ã‚¹ã‚¯æ•°ï¼ˆè² è·åˆ†æ•£ã®èª¿æ•´ç”¨ï¼‰
    worker_prefetch_multiplier=1,
    # ã‚¿ã‚¹ã‚¯ãŒ ACK ã•ã‚Œã‚‹ã‚¿ã‚¤ãƒŸãƒ³ã‚°ï¼ˆå®Ÿè¡Œå®Œäº†å¾Œã‚’æ¨å¥¨ï¼‰
    task_acks_late=True,
)
```

`task_acks_late=True` ã¯ãƒ¯ãƒ¼ã‚«ãƒ¼ãŒã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã—ãŸéš›ã®ã‚¿ã‚¹ã‚¯ãƒ­ã‚¹ãƒˆã‚’é˜²ãé‡è¦ãªè¨­å®šã§ã™ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ã¯ Broker ã‹ã‚‰ã‚¿ã‚¹ã‚¯ã‚’å—ã‘å–ã£ãŸæ™‚ç‚¹ã§ ACK ã•ã‚Œã¾ã™ãŒã€ã“ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æœ‰åŠ¹ã«ã™ã‚‹ã¨å®Ÿè¡Œå®Œäº†å¾Œã« ACK ã•ã‚Œã‚‹ãŸã‚ã€æœªå®Œäº†ã‚¿ã‚¹ã‚¯ãŒå†ã‚­ãƒ¥ãƒ¼ã‚¤ãƒ³ã‚°ã•ã‚Œã¾ã™ã€‚

### Redis æ¥ç¶šã® SSL å¯¾å¿œ

æœ¬ç•ªç’°å¢ƒã§ã¯ Redis ãŒ SSL å¯¾å¿œã—ã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã§ã™ã€‚

```python
import ssl

app.conf.update(
    broker_url="rediss://:password@your-redis-host:6380/0",
    result_backend="rediss://:password@your-redis-host:6380/0",
    broker_use_ssl={
        "ssl_cert_reqs": ssl.CERT_REQUIRED,
        "ssl_ca_certs": "/path/to/ca-cert.pem",
    },
    redis_backend_use_ssl={
        "ssl_cert_reqs": ssl.CERT_REQUIRED,
        "ssl_ca_certs": "/path/to/ca-cert.pem",
    },
)
```

ã‚¹ã‚­ãƒ¼ãƒ ã‚’ `redis://` ã‹ã‚‰ `rediss://` ã«å¤‰ãˆã‚‹ã ã‘ã§ TLS ãŒæœ‰åŠ¹ã«ãªã‚Šã¾ã™ã€‚

## ã‚¿ã‚¹ã‚¯ã®å®šç¾©ã¨å®Ÿè¡Œ

### åŸºæœ¬çš„ãªã‚¿ã‚¹ã‚¯å®šç¾©

```python
# tasks/email_tasks.py
from celery_app import app
import time


@app.task(name="tasks.send_welcome_email")
def send_welcome_email(user_id: int, email: str) -> dict:
    """ã‚¦ã‚§ãƒ«ã‚«ãƒ ãƒ¡ãƒ¼ãƒ«ã‚’é€ä¿¡ã™ã‚‹ã‚¿ã‚¹ã‚¯"""
    # å®Ÿéš›ã®ãƒ¡ãƒ¼ãƒ«é€ä¿¡å‡¦ç†ï¼ˆã“ã“ã§ã¯ä»®å®Ÿè£…ï¼‰
    time.sleep(2)  # å¤–éƒ¨ SMTP ã¸ã®é€šä¿¡ã‚’æ¨¡æ“¬
    return {
        "status": "sent",
        "user_id": user_id,
        "email": email,
    }


@app.task(
    name="tasks.generate_report",
    bind=True,           # selfï¼ˆã‚¿ã‚¹ã‚¯ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ï¼‰ã‚’ç¬¬1å¼•æ•°ã§å—ã‘å–ã‚‹
    max_retries=3,
    default_retry_delay=60,
)
def generate_report(self, report_id: int) -> dict:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚¿ã‚¹ã‚¯ï¼ˆãƒªãƒˆãƒ©ã‚¤è¨­å®šä»˜ãï¼‰"""
    try:
        # é‡ã„å‡¦ç†
        time.sleep(5)
        return {"report_id": report_id, "url": f"/reports/{report_id}.pdf"}
    except Exception as exc:
        raise self.retry(exc=exc, countdown=2 ** self.request.retries * 10)
```

### ã‚¿ã‚¹ã‚¯ã®å®Ÿè¡Œæ–¹æ³•

```python
# .delay() â€” æœ€ã‚‚ã‚·ãƒ³ãƒ—ãƒ«ãªéåŒæœŸå®Ÿè¡Œ
result = send_welcome_email.delay(user_id=1, email="user@example.com")
print(result.id)  # "3e4a5b6c-..."ï¼ˆã‚¿ã‚¹ã‚¯ IDï¼‰

# .apply_async() â€” è©³ç´°ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’æŒ‡å®šã™ã‚‹å ´åˆ
result = send_welcome_email.apply_async(
    args=[1, "user@example.com"],
    countdown=30,          # 30ç§’å¾Œã«å®Ÿè¡Œ
    expires=3600,          # 1æ™‚é–“ä»¥å†…ã«å®Ÿè¡Œã•ã‚Œãªã‘ã‚Œã°ç ´æ£„
    queue="high_priority", # ç‰¹å®šã®ã‚­ãƒ¥ãƒ¼ã«é€ä¿¡
)

# åŒæœŸå®Ÿè¡Œï¼ˆãƒ†ã‚¹ãƒˆãƒ»ãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
result = send_welcome_email.apply(args=[1, "user@example.com"])
print(result.result)
```

### çµæœã®å–å¾—

```python
from celery.result import AsyncResult
from celery_app import app


def get_task_status(task_id: str) -> dict:
    result = AsyncResult(task_id, app=app)

    response = {"task_id": task_id, "state": result.state}

    if result.state == "PENDING":
        response["info"] = "ã‚¿ã‚¹ã‚¯ã¯ã‚­ãƒ¥ãƒ¼å¾…ã¡ã€ã¾ãŸã¯å­˜åœ¨ã—ã¾ã›ã‚“"
    elif result.state == "STARTED":
        response["info"] = "å®Ÿè¡Œä¸­"
    elif result.state == "SUCCESS":
        response["result"] = result.result
    elif result.state == "FAILURE":
        response["error"] = str(result.info)
    elif result.state == "RETRY":
        response["info"] = "ãƒªãƒˆãƒ©ã‚¤å¾…ã¡"

    return response
```

## FastAPI ã¨ã®çµ±åˆ

FastAPI ã¨ã®çµ±åˆã§ã¯ã€ã‚¿ã‚¹ã‚¯ã®æŠ•å…¥ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã¨çµæœç¢ºèªã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’åˆ†é›¢ã™ã‚‹ã®ãŒåŸºæœ¬ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚

```python
# main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from celery.result import AsyncResult
from tasks.email_tasks import send_welcome_email, generate_report
from celery_app import app as celery_app

api = FastAPI()


class EmailRequest(BaseModel):
    user_id: int
    email: str


class TaskResponse(BaseModel):
    task_id: str
    status: str


@api.post("/users/{user_id}/welcome-email", response_model=TaskResponse, status_code=202)
async def enqueue_welcome_email(user_id: int, body: EmailRequest):
    """ãƒ¡ãƒ¼ãƒ«é€ä¿¡ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€ï¼ˆå³åº§ã« 202 ã‚’è¿”ã™ï¼‰"""
    task = send_welcome_email.apply_async(
        args=[user_id, body.email],
        queue="email",
    )
    return TaskResponse(task_id=task.id, status="queued")


@api.get("/tasks/{task_id}", response_model=dict)
async def get_task_result(task_id: str):
    """ã‚¿ã‚¹ã‚¯ã®çŠ¶æ…‹ã¨çµæœã‚’è¿”ã™"""
    result = AsyncResult(task_id, app=celery_app)

    if result.state == "PENDING":
        return {"task_id": task_id, "state": "PENDING"}
    elif result.state == "SUCCESS":
        return {"task_id": task_id, "state": "SUCCESS", "result": result.result}
    elif result.state == "FAILURE":
        raise HTTPException(
            status_code=500,
            detail={"task_id": task_id, "state": "FAILURE", "error": str(result.info)},
        )
    else:
        return {"task_id": task_id, "state": result.state}


@api.post("/reports", response_model=TaskResponse, status_code=202)
async def enqueue_report(report_id: int):
    task = generate_report.apply_async(args=[report_id], queue="reports")
    return TaskResponse(task_id=task.id, status="queued")
```

FastAPI ã® `BackgroundTasks` ã¨ã®é•ã„ã«æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚`BackgroundTasks` ã¯ãƒ—ãƒ­ã‚»ã‚¹å†…ã§å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€ã‚µãƒ¼ãƒãƒ¼ãŒè½ã¡ã‚‹ã¨ã‚¿ã‚¹ã‚¯ãŒæ¶ˆãˆã¾ã™ã€‚Celery ã¯åˆ¥ãƒ—ãƒ­ã‚»ã‚¹ï¼ˆåˆ¥ã‚³ãƒ³ãƒ†ãƒŠï¼‰ã§å‹•ä½œã™ã‚‹ãŸã‚ã€è€éšœå®³æ€§ãŒé«˜ãã€ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚‚å®¹æ˜“ã§ã™ã€‚

## ã‚¿ã‚¹ã‚¯ãƒã‚§ãƒ¼ãƒ³ãƒ»ã‚°ãƒ«ãƒ¼ãƒ—ãƒ»ã‚³ãƒ¼ãƒ‰

Celery Canvas ã‚’ä½¿ã†ã¨è¤‡æ•°ã‚¿ã‚¹ã‚¯ã®ä¾å­˜é–¢ä¿‚ã‚’å®£è¨€çš„ã«è¨˜è¿°ã§ãã¾ã™ã€‚

### chain â€” é †æ¬¡å®Ÿè¡Œ

```python
from celery import chain
from tasks.report_tasks import fetch_data, process_data, generate_pdf, notify_user

# å‰ã®ã‚¿ã‚¹ã‚¯ã®æˆ»ã‚Šå€¤ãŒæ¬¡ã®ã‚¿ã‚¹ã‚¯ã®ç¬¬1å¼•æ•°ã«æ¸¡ã•ã‚Œã‚‹
pipeline = chain(
    fetch_data.s(dataset_id=42),
    process_data.s(),
    generate_pdf.s(),
    notify_user.s(email="admin@example.com"),
)
result = pipeline.apply_async()
```

### group â€” ä¸¦åˆ—å®Ÿè¡Œ

```python
from celery import group

# è¤‡æ•°ã®ã‚¿ã‚¹ã‚¯ã‚’åŒæ™‚ã«å®Ÿè¡Œã—ã€å…¨çµæœã‚’ãƒªã‚¹ãƒˆã§è¿”ã™
parallel_tasks = group(
    send_welcome_email.s(user_id=1, email="a@example.com"),
    send_welcome_email.s(user_id=2, email="b@example.com"),
    send_welcome_email.s(user_id=3, email="c@example.com"),
)
result = parallel_tasks.apply_async()
print(result.get())  # [{"status": "sent", ...}, ...]
```

### chord â€” ä¸¦åˆ—å®Ÿè¡Œ + ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯

```python
from celery import chord
from tasks.report_tasks import process_chunk, merge_results

# ã‚°ãƒ«ãƒ¼ãƒ—å…¨ä½“ãŒå®Œäº†ã—ãŸå¾Œã«ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’å®Ÿè¡Œ
workflow = chord(
    group(
        process_chunk.s(chunk_id=i)
        for i in range(10)
    ),
    merge_results.s(),  # 10ã‚¿ã‚¹ã‚¯ã®çµæœãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚‹
)
result = workflow.apply_async()
```

chord ã§ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®ã„ãšã‚Œã‹1ã‚¿ã‚¹ã‚¯ãŒå¤±æ•—ã™ã‚‹ã¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¯å®Ÿè¡Œã•ã‚Œã¾ã›ã‚“ã€‚å¾Œå‡¦ç†ã® `on_chord_error` ã‚’è¨­å®šã™ã‚‹ã‹ã€å€‹ã€…ã®ã‚¿ã‚¹ã‚¯ã«ãƒªãƒˆãƒ©ã‚¤ã‚’è¨­å®šã™ã‚‹ã“ã¨ã§å¯¾å‡¦ã—ã¾ã™ã€‚

## Celery Beat ã§ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚°

Celery Beat ã¯ãƒãƒƒãƒå‡¦ç†ã‚„å®šæœŸãƒ¬ãƒãƒ¼ãƒˆé€ä¿¡ãªã©ã®ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼ã§ã™ã€‚Beat ãƒ—ãƒ­ã‚»ã‚¹è‡ªä½“ã¯ã‚¿ã‚¹ã‚¯ã‚’å®Ÿè¡Œã›ãšã€ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ã«å¾“ã£ã¦ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ¥ãƒ¼ã«ç©ã‚€å½¹å‰²ã ã‘ã‚’æ‹…ã„ã¾ã™ã€‚

### ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š

```python
# celery_app.py ã«è¿½è¨˜
from celery.schedules import crontab
from datetime import timedelta

app.conf.beat_schedule = {
    # 30ç§’ã”ã¨ã«ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    "health-check-every-30s": {
        "task": "tasks.health_check",
        "schedule": timedelta(seconds=30),
    },
    # æ¯æœ9æ™‚ã«ãƒ‡ã‚¤ãƒªãƒ¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
    "daily-report-at-9am": {
        "task": "tasks.generate_daily_report",
        "schedule": crontab(hour=9, minute=0),
        "args": ("daily",),
    },
    # æ¯é€±æœˆæ›œ0æ™‚ã«é€±æ¬¡é›†è¨ˆ
    "weekly-summary-monday": {
        "task": "tasks.generate_weekly_summary",
        "schedule": crontab(hour=0, minute=0, day_of_week="monday"),
    },
    # æ¯æœˆ1æ—¥8æ™‚ã«è«‹æ±‚æ›¸ã‚’ç”Ÿæˆ
    "monthly-invoice-1st": {
        "task": "tasks.generate_invoices",
        "schedule": crontab(hour=8, minute=0, day_of_month="1"),
    },
}
```

### crontab ã®ã‚ˆãä½¿ã†ãƒ‘ã‚¿ãƒ¼ãƒ³

| è¨˜è¿° | å®Ÿè¡Œã‚¿ã‚¤ãƒŸãƒ³ã‚° |
|---|---|
| `crontab()` | æ¯åˆ† |
| `crontab(minute=0)` | æ¯æ™‚0åˆ† |
| `crontab(hour=8, minute=30)` | æ¯æ—¥8:30 |
| `crontab(day_of_week="mon-fri", hour=9)` | å¹³æ—¥æ¯æœ9æ™‚ |
| `crontab(day_of_month="1", hour=0)` | æ¯æœˆ1æ—¥0æ™‚ |
| `crontab(month_of_year="1,7", day_of_month="1")` | 1æœˆãƒ»7æœˆ1æ—¥ |

### Beat ã®èµ·å‹•

```bash
# Beat ãƒ—ãƒ­ã‚»ã‚¹ã‚’èµ·å‹•ï¼ˆã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼å°‚ç”¨ï¼‰
celery -A celery_app beat --loglevel=info

# Worker ã¨ Beat ã‚’åŒä¸€ãƒ—ãƒ­ã‚»ã‚¹ã§èµ·å‹•ï¼ˆé–‹ç™ºãƒ»å°è¦æ¨¡ç”¨ï¼‰
celery -A celery_app worker --beat --loglevel=info
```

æœ¬ç•ªç’°å¢ƒã§ã¯ Beat ã¨ Worker ã¯å¿…ãšåˆ¥ãƒ—ãƒ­ã‚»ã‚¹ã§å‹•ã‹ã—ã¾ã™ã€‚Beat ã‚’è¤‡æ•°ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹èµ·å‹•ã™ã‚‹ã¨ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒäºŒé‡å®Ÿè¡Œã•ã‚Œã‚‹ãŸã‚ã€Beat ã¯å¸¸ã«1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿ã§ã™ã€‚

## ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒªãƒˆãƒ©ã‚¤

### autoretry_for ã«ã‚ˆã‚‹è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤

```python
from celery_app import app
import requests
from requests.exceptions import ConnectionError, Timeout


@app.task(
    bind=True,
    autoretry_for=(ConnectionError, Timeout),  # ã“ã‚Œã‚‰ã®ä¾‹å¤–ã§è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
    retry_backoff=True,          # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã‚’æœ‰åŠ¹åŒ–
    retry_backoff_max=600,       # ãƒãƒƒã‚¯ã‚ªãƒ•ã®ä¸Šé™ï¼ˆç§’ï¼‰
    retry_jitter=True,           # ã‚µãƒ³ãƒ€ãƒªãƒ³ã‚°ãƒãƒ¼ãƒ‰é˜²æ­¢ã®ãƒ©ãƒ³ãƒ€ãƒ æºã‚‰ã
    max_retries=5,
    name="tasks.call_external_api",
)
def call_external_api(self, endpoint: str, payload: dict) -> dict:
    response = requests.post(endpoint, json=payload, timeout=30)
    response.raise_for_status()
    return response.json()
```

`retry_backoff=True` ã‚’è¨­å®šã™ã‚‹ã¨ã€1å›ç›®ã®ãƒªãƒˆãƒ©ã‚¤ã¯1ç§’å¾Œã€2å›ç›®ã¯2ç§’å¾Œã€3å›ç›®ã¯4ç§’å¾Œâ€¦ã¨æŒ‡æ•°çš„ã«é–“éš”ãŒä¼¸ã³ã¾ã™ã€‚`retry_jitter=True` ã¯ãƒ©ãƒ³ãƒ€ãƒ ãªæºã‚‰ãã‚’åŠ ãˆã¦ã€åŒæ™‚ã«å¤±æ•—ã—ãŸå¤§é‡ã‚¿ã‚¹ã‚¯ãŒä¸€æ–‰ã«ãƒªãƒˆãƒ©ã‚¤ã™ã‚‹ã€Œã‚µãƒ³ãƒ€ãƒªãƒ³ã‚°ãƒãƒ¼ãƒ‰ã€ã‚’é˜²ãã¾ã™ã€‚

### æ‰‹å‹•ãƒªãƒˆãƒ©ã‚¤ã¨æ®µéšçš„ãƒãƒƒã‚¯ã‚ªãƒ•

```python
@app.task(bind=True, max_retries=3, name="tasks.process_payment")
def process_payment(self, order_id: int, amount: float) -> dict:
    try:
        result = payment_gateway.charge(order_id, amount)
        return {"order_id": order_id, "charge_id": result.id}
    except payment_gateway.RateLimitError as exc:
        # ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«å¿œã˜ã¦ãƒãƒƒã‚¯ã‚ªãƒ•æ™‚é–“ã‚’å¢—ã‚„ã™
        delay = 2 ** self.request.retries * 10  # 10s, 20s, 40s
        raise self.retry(exc=exc, countdown=delay)
    except payment_gateway.CardDeclinedError:
        # ãƒªãƒˆãƒ©ã‚¤ã—ã¦ã‚‚æ„å‘³ãŒãªã„ã‚¨ãƒ©ãƒ¼ã¯å³åº§ã«å¤±æ•—
        raise
```

### ã‚¿ã‚¹ã‚¯ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ãƒ•ãƒƒã‚¯

```python
@app.task(
    bind=True,
    name="tasks.import_csv",
    on_failure=on_task_failure,  # å¤±æ•—æ™‚ã®ãƒ•ãƒƒã‚¯
)
def import_csv(self, file_path: str) -> dict:
    ...


def on_task_failure(self, exc, task_id, args, kwargs, einfo):
    """ã‚¿ã‚¹ã‚¯å¤±æ•—æ™‚ã« Slack é€šçŸ¥ã‚’é€ã‚‹ä¾‹"""
    slack_client.post_message(
        channel="#alerts",
        text=f"ã‚¿ã‚¹ã‚¯å¤±æ•—: {task_id}\nä¾‹å¤–: {exc}\nå¼•æ•°: {args}",
    )
```

## Flower ã§ã®ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

Flower ã¯ Celery ã®ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ã™ã€‚Worker ã®çŠ¶æ…‹ãƒ»ã‚¿ã‚¹ã‚¯ã®ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆãƒ»ã‚­ãƒ¥ãƒ¼ã®æ·±ã•ã‚’ Web UI ã§ç¢ºèªã§ãã¾ã™ã€‚

### èµ·å‹•æ–¹æ³•

```bash
# åŸºæœ¬èµ·å‹•ï¼ˆ:5555 ã§ã‚¢ã‚¯ã‚»ã‚¹ï¼‰
celery -A celery_app flower --port=5555

# èªè¨¼ä»˜ãèµ·å‹•ï¼ˆæœ¬ç•ªç’°å¢ƒã§ã¯å¿…é ˆï¼‰
celery -A celery_app flower \
    --port=5555 \
    --basic_auth=admin:secretpassword \
    --url_prefix=flower  # ãƒªãƒãƒ¼ã‚¹ãƒ—ãƒ­ã‚­ã‚·é…ä¸‹ã®å ´åˆ
```

### Flower API ã‚’ä½¿ã£ãŸè‡ªå‹•åŒ–

Flower ã¯ REST API ã‚‚æä¾›ã—ã¦ãŠã‚Šã€ç›£è¦–ã‚·ã‚¹ãƒ†ãƒ ã‚„ CI ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨é€£æºã§ãã¾ã™ã€‚

```python
import httpx


async def get_celery_stats() -> dict:
    """Flower API ã‹ã‚‰ãƒ¯ãƒ¼ã‚«ãƒ¼çµ±è¨ˆã‚’å–å¾—"""
    async with httpx.AsyncClient() as client:
        resp = await client.get(
            "http://flower:5555/api/workers",
            auth=("admin", "secretpassword"),
        )
        return resp.json()


async def revoke_task(task_id: str) -> bool:
    """å®Ÿè¡Œä¸­ãƒ»å¾…æ©Ÿä¸­ã®ã‚¿ã‚¹ã‚¯ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«"""
    async with httpx.AsyncClient() as client:
        resp = await client.post(
            f"http://flower:5555/api/task/revoke/{task_id}",
            json={"terminate": True},
            auth=("admin", "secretpassword"),
        )
        return resp.status_code == 200
```

### Cloud Run ã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤

Flower ã‚’ Cloud Run ã«ãƒ‡ãƒ—ãƒ­ã‚¤ã™ã‚‹å ´åˆã€èªè¨¼ã¯ IAPï¼ˆIdentity-Aware Proxyï¼‰ã¾ãŸã¯ Cloud Run ã®çµ„ã¿è¾¼ã¿èªè¨¼ã«ä»»ã›ã€`--basic_auth` ã¯çœç•¥ã§ãã¾ã™ã€‚

```dockerfile
# Dockerfile.flower
FROM python:3.12-slim
RUN pip install celery[redis] flower
CMD ["celery", "-A", "celery_app", "flower", "--port=8080", "--address=0.0.0.0"]
```

```yaml
# Cloud Run Serviceï¼ˆgcloud run deploy ã‚³ãƒãƒ³ãƒ‰ã®ä»£ã‚ã‚Šã« YAML ã§ç®¡ç†ï¼‰
# gcloud run services replace flower-service.yaml
apiVersion: serving.knative.dev/v1
kind: Service
metadata:
  name: celery-flower
spec:
  template:
    spec:
      containers:
        - image: gcr.io/PROJECT_ID/celery-flower
          ports:
            - containerPort: 8080
          env:
            - name: REDIS_URL
              valueFrom:
                secretKeyRef:
                  name: redis-url
                  key: latest
```

## Docker Compose æ§‹æˆ

ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã¨ CI ã§ä½¿ãˆã‚‹å®Œå…¨ãª Docker Compose æ§‹æˆã§ã™ã€‚

```yaml
# docker-compose.yml
version: "3.9"

services:
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  api:
    build: .
    command: uvicorn main:api --host 0.0.0.0 --port 8000 --reload
    ports:
      - "8000:8000"
    volumes:
      - .:/app
    environment:
      REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy

  worker:
    build: .
    command: celery -A celery_app worker --loglevel=info --concurrency=4 -Q default,email,reports
    volumes:
      - .:/app
    environment:
      REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    deploy:
      replicas: 2  # ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’2å°èµ·å‹•

  beat:
    build: .
    command: celery -A celery_app beat --loglevel=info --scheduler django_celery_beat.schedulers:DatabaseScheduler
    volumes:
      - .:/app
    environment:
      REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
    # Beat ã¯å¿…ãš1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®ã¿
    deploy:
      replicas: 1

  flower:
    build: .
    command: celery -A celery_app flower --port=5555 --basic_auth=admin:dev_password
    ports:
      - "5555:5555"
    environment:
      REDIS_URL: redis://redis:6379/0
    depends_on:
      redis:
        condition: service_healthy
```

`worker` ã« `deploy.replicas: 2` ã‚’æŒ‡å®šã™ã‚‹ã“ã¨ã§ã€ãƒ¯ãƒ¼ã‚«ãƒ¼ã‚’2å°ä¸¦åˆ—ã§å‹•ã‹ã›ã¾ã™ã€‚å„ãƒ¯ãƒ¼ã‚«ãƒ¼ã¯ç‹¬ç«‹ã—ãŸãƒ—ãƒ­ã‚»ã‚¹ã¨ã—ã¦ã‚­ãƒ¥ãƒ¼ã‚’ç›£è¦–ã—ã€æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒ«ã—ã¾ã™ã€‚

ã‚­ãƒ¥ãƒ¼ã®åˆ†é›¢ï¼ˆ`-Q default,email,reports`ï¼‰ã¯é‡è¦ãªè¨­è¨ˆãƒã‚¤ãƒ³ãƒˆã§ã™ã€‚é‡è¦åº¦ã®é«˜ã„ã‚¿ã‚¹ã‚¯ã‚’å°‚ç”¨ã‚­ãƒ¥ãƒ¼ã«é€ã‚‹ã“ã¨ã§ã€ä½å„ªå…ˆåº¦ã®å¤§é‡ã‚¿ã‚¹ã‚¯ã«ã‚ˆã£ã¦é‡è¦ã‚¿ã‚¹ã‚¯ãŒè©°ã¾ã‚‹ã“ã¨ã‚’é˜²ã’ã¾ã™ã€‚

## ã¾ã¨ã‚

Celery + Redis ã®æ§‹æˆã‚’æ”¹ã‚ã¦æ•´ç†ã—ã¾ã™ã€‚

| é …ç›® | æ¨å¥¨è¨­å®šãƒ»æ–¹é‡ |
|---|---|
| Broker / Backend | ä¸¡æ–¹ Redisï¼ˆé–‹ç™ºãƒ»ä¸­è¦æ¨¡ï¼‰ã€‚æœ¬ç•ªå¤§è¦æ¨¡ã§ã¯ Broker ã« RabbitMQ ã‚‚æ¤œè¨ |
| ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ | JSONï¼ˆ`task_serializer="json"`ï¼‰ã€‚pickle ã¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã‚ã‚Š |
| ACK ã‚¿ã‚¤ãƒŸãƒ³ã‚° | `task_acks_late=True`ï¼ˆè€éšœå®³æ€§ã®ãŸã‚ï¼‰ |
| ãƒªãƒˆãƒ©ã‚¤ | `autoretry_for` + `retry_backoff=True` + `retry_jitter=True` |
| ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒªãƒ³ã‚° | Beat ãƒ—ãƒ­ã‚»ã‚¹ã¯å¿…ãš1ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ |
| ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚° | Flower + æœ¬ç•ªã¯ Basic Auth ã¾ãŸã¯ IAP |
| ã‚­ãƒ¥ãƒ¼è¨­è¨ˆ | å„ªå…ˆåº¦ãƒ»ç¨®é¡åˆ¥ã«ã‚­ãƒ¥ãƒ¼ã‚’åˆ†ã‘ã‚‹ |

Celery ã¯è¨­å®šé …ç›®ãŒå¤šãã€æœ€åˆã¯æˆ¸æƒ‘ã†ã“ã¨ã‚‚ã‚ã‚Šã¾ã™ã€‚ã—ã‹ã—å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒå……å®Ÿã—ã¦ãŠã‚Šã€FastAPI ã‚„ Django ã¨ã®çµ±åˆäº‹ä¾‹ã‚‚è±Šå¯Œã§ã™ã€‚Docker Compose ã§æ‰‹å…ƒã«ç’°å¢ƒã‚’ç«‹ã¡ä¸Šã’ã€ã¾ãš `send_task.delay()` ã®1è¡Œã‹ã‚‰å§‹ã‚ã¦ã¿ã¦ãã ã•ã„ã€‚ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ã®è¨­è¨ˆã¯ã€ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ãªã‚·ã‚¹ãƒ†ãƒ ã®åŸºç›¤ã¨ãªã‚Šã¾ã™ã€‚

---

å‚è€ƒãƒªã‚½ãƒ¼ã‚¹:

- [Celery å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.celeryq.dev/en/stable/)
- [Using Redis â€” Celery 5.6.2](https://docs.celeryq.dev/en/stable/getting-started/backends-and-brokers/redis.html)
- [Canvas: Designing Work-flows](https://docs.celeryq.dev/en/stable/userguide/canvas.html)
- [Periodic Tasks â€” Celery 5.6.0](https://docs.celeryq.dev/en/latest/userguide/periodic-tasks.html)
