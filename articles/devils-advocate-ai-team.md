---
title: "デビルズアドボケイトをAI開発チームに入れたら品質が劇的に改善した話"
emoji: "😈"
type: "tech"
topics: ["Claude", "AI", "品質管理", "開発手法"]
published: false
---

## はじめに

Claude Code Agent Teamsのようなマルチエージェント開発環境が登場し、AIエージェントにチームを組ませてソフトウェア開発を行う時代が始まった。設計担当、実装担当、ドキュメント担当――複数のAIエージェントがそれぞれの役割を持ち、並列にタスクを処理する。効率は確かに上がる。

しかし、ここに一つ見落とされがちな問題がある。**全員が協調的なチームには、批判的な視点が生まれない**ということだ。

AIエージェントは基本的に「与えられたタスクを遂行する」ように動く。設計を依頼されれば設計し、実装を依頼されれば実装する。だが「この設計には致命的な欠陥がある」「この工数見積もりは楽観的すぎる」と声を上げるエージェントは、意図的に配置しない限り存在しない。

私はこの問題に対する解として、AIチームに**デビルズアドボケイト（DA）**を必須メンバーとして組み込む運用を始めた。結果、3ラウンドのレビューを経て、R2時点で高重要度9件あった問題が**最終的に1件まで激減**した。本記事では、その実践と知見を共有する。

## デビルズアドボケイトとは

デビルズアドボケイト（Devil's Advocate、悪魔の代弁者）とは、集団の意思決定において**意図的に反対意見を述べる役割**を指す。元はカトリック教会の列聖審査で、聖人候補に対してあえて反論する役職だった。

ソフトウェア開発の世界でも、コードレビューや設計レビューの場面でこの役割は重要視されている。全員が「良さそうだ」と思っている設計にこそ、盲点が潜んでいる。

AIエージェントチームにこれを応用する。つまり、チームの成果物に対して**忖度なく問題点を指摘する専用エージェント**を1台設ける。他のエージェントが作り上げた成果物を、攻撃者の目線、運用者の目線、コスト管理者の目線で徹底的に検証する。

## なぜAI開発チームにDAが必要か

### AIエージェントの「忖度」問題

LLMベースのAIエージェントには、ユーザーの意図に沿おうとする傾向がある。「この設計で良いか確認して」と依頼すると、問題を指摘するよりも「良い設計です」と応答しやすい。これはLLMの学習特性に起因するもので、意図的に「批判せよ」と指示しない限り、本質的な問題を見逃す可能性がある。

### 同じ基盤モデルの限界

Agent Teamsの各エージェントは同じLLM（例えばClaude）をベースにしている。同じモデルが設計し、同じモデルがレビューする構造では、**モデル固有のバイアスを検出できない**。人間のチームであれば、異なる経験や専門性を持つメンバーが自然と多角的な視点を提供する。AIチームでは、それを意図的に設計する必要がある。

### データで見る「レビューの効果」

Qodoの「[State of AI code quality](https://www.qodo.ai/reports/state-of-ai-code-quality/)」レポート（2025年、600名超の開発者調査）によれば、AIが生成したコードに対してレビューを統合したチームの品質改善率は**81%**に達する。レビューなしのチームでは**55%**にとどまる。

レビューは効果がある。そして**批判的なレビュー**は、協調的なレビューよりもさらに効果が高い。

## 実践: Claude Code Agent TeamsでのDA導入

### チーム構成

私が実際に運用したチームは以下の5エージェント構成だ。

```
チーム: 5エージェント構成

1. organizer     - タスク整理・優先度判断
2. documenter    - ドキュメント作成・更新
3. designer      - 設計書作成
4. security      - セキュリティ監査
5. devils-advocate - 全成果物の批判的レビュー（DA）
```

DAエージェントは他の全エージェントの完了を待ってから起動する。これは`addBlockedBy`で依存関係を設定することで実現できる。

### DAエージェントのプロンプト

実際に使用したDAエージェントのプロンプトは以下の通りだ。

```
あなたはデビルズアドボケイトです。
チームメンバーが作成した全ての成果物を批判的にレビューしてください。

方針:
- 忖度なし。問題点を正直に指摘する
- 見落とされているリスク・前提条件の誤りを洗い出す
- 実行可能性の問題を検証する
- コスト試算の甘さを指摘する

指摘の分類:
- [高] セキュリティ脆弱性、認証バグ、データ損失リスク
- [中] 設計の矛盾、工数見積もりの甘さ、テスト不足
- [低] 命名規則、ドキュメントの体裁、改善提案

出力形式:
- 成果物ごとにセクションを分ける
- 各指摘に重要度タグ [高][中][低] を付ける
- 最後に「改善提案」を列挙する
```

ポイントは「忖度なし」を明示的に指示することだ。これがないと、AIは他のエージェントの成果を肯定的に評価する傾向を見せる。

### マルチラウンドレビューの威力

DA導入の真価は、**マルチラウンドレビュー**で発揮される。1回のレビューで終わらせず、修正後に再度DAを走らせることで、修正に伴う新たな問題や反映漏れを検出する。

#### Round 1: 初回レビュー

DAは朝会ボット設計書、判断記録、環境設計の3つの成果物をレビューし、以下を検出した。

- **高重要度7件、中重要度7件、低重要度3件**

特に深刻だったのは以下の3つだ。

**1. 認証コードのバグ**

```python
if SCHEDULER_SECRET and auth != f"Bearer {SCHEDULER_SECRET}":
    return {"error": "Unauthorized"}, 401
```

この条件式では、環境変数 `SCHEDULER_SECRET` が未設定（空文字）の場合、認証チェック自体がスキップされる。つまり**環境変数の設定を忘れただけで、全リクエストが認証なしで通る**。

DAはこれを[高]指摘として検出し、さらに認証方式自体をBearer Token方式からOIDCトークン方式への変更を提案した。

**2. 工数見積もりの甘さ**

設計書では「合計工数: 約16時間（3日間）」と見積もられていたが、DAは以下を指摘した。

- 依存するBigQueryテーブル5つのうち4つが未作成
- テスト工数が「手動テスト1h」のみ
- freee APIのトークンリフレッシュ処理が未考慮
- Secret Manager連携の工数が未算入

DAの推定では**30-40時間**が現実的な工数であり、最終的には**35-45時間**に修正された。見積もりが倍以上に膨らんだことになる。もし元の見積もりで開発を始めていたら、スケジュール崩壊は確実だった。

**3. ドキュメント内の矛盾**

OIDC認証方式に変更したにもかかわらず、環境変数一覧に旧方式の `SCHEDULER_SECRET` が残存していた。同一ドキュメント内で認証方式に関する矛盾が3箇所もあり、このまま実装すれば混乱は避けられなかった。

#### Round 2: 修正確認 + 新規問題の検出

R1の指摘を受けて修正を行い、再度DAを走らせた。結果は厳しかった。

- **R1指摘の反映率: わずか35%**（17項目中6項目のみ対応）
- **新たに高重要度9件を検出**

セキュリティ関連の指摘は迅速に対応されたが、工数見積もり・テスト戦略・監視設計といった「プロジェクトの実行可能性」に直結する指摘がすべて未対応だった。DAは「**現状では実行可能なレベルに達していない**」と判定した。

人間であれば「まあいいか」と流してしまいそうな指摘を、DAは容赦なく追跡する。これがAI DAの強みだ。

#### Round 3: 最終レビュー

R2の指摘を全て反映した上で、最終ラウンドのDAを実行した。

結果は劇的だった。

- **R1指摘の反映率: 100%**（18/18項目）
- **R2指摘の反映率: 100%**（6/6項目）
- **高重要度の問題: 9件 → 1件**

残る1件も「Agent Teams記事の差別化窓が狭くなっている」という記事戦略の話であり、設計上の欠陥ではなかった。DAは「**全成果物は実行可能なレベルに達している**」と最終判定を下した。

### Before/After比較

| 指標 | DA導入前 | R1後 | R3後 |
|------|---------|------|------|
| 高重要度の問題 | 未検出 | R1: 7件→R2: 9件 | 1件 |
| 認証設計 | バグあり（全リクエスト通過の危険性） | 指摘 | OIDC完全移行 |
| 工数見積もり | 16h（非現実的） | 30-40h推奨 | 35-45hに修正 |
| テスト戦略 | 手動テスト1hのみ | 不足を指摘 | 包括的テスト設計（8シナリオ） |
| 監視設計 | なし | 不足を指摘 | Cloud Monitoring + アラート設計 |
| ドキュメント品質 | 矛盾3箇所 | 部分修正 | 矛盾解消 |

## DA導入方法（実践ガイド）

### チーム編成のパターン

**最小構成（3エージェント）**

```
1. implementer  - 実装担当
2. reviewer     - コードレビュー担当
3. devils-advocate - 批判的レビュー
```

1人の実装者と1人のレビュアーだけでは見逃す問題を、DAが拾う構成。個人開発者にとっては「自分以外の目」をAIで3つ確保できる。

**標準構成（5エージェント）**

```
1. designer     - 設計担当
2. implementer  - 実装担当
3. documenter   - ドキュメント担当
4. tester       - テスト担当
5. devils-advocate - 批判的レビュー
```

本記事で紹介した実績はこの規模のチームによるもの。

### DAエージェントの起動タイミング

DAは他のエージェントの成果物が揃ってからレビューする必要がある。Claude Code Agent Teamsでは、タスクの`addBlockedBy`を設定することで、依存関係を制御できる。

```
# DAタスクを作成し、他のエージェントのタスクに依存させる
TaskCreate: "全成果物の批判的レビュー"
TaskUpdate: addBlockedBy: [task-1, task-2, task-3, task-4]
```

これにより、全エージェントのタスクが完了した後にDAが自動的に起動する。

### マルチラウンドのコツ

| ラウンド | 目的 | 重視する観点 |
|---------|------|-------------|
| R1 | 広範なレビュー | セキュリティ、設計欠陥、前提条件の誤り |
| R2 | R1反映の確認 + 新規問題の検出 | 反映率の追跡、修正に伴う矛盾 |
| R3 | 最終確認 + 実行可能性判定 | 全指摘の対応状況、「実装に着手してよいか」の判断 |

実体験から言えば、**R2が最も重要**だ。R1の指摘をどれだけ反映したかを追跡し、反映率を数値で示すことで、チーム（あるいは自分自身）の対応漏れが可視化される。私のケースではR2で反映率35%という現実を突きつけられ、R3に向けて全項目を対応するきっかけになった。

### CLAUDE.mdへのルール定着

一度DAの効果を実感したら、チーム編成ルールとして定着させることを勧める。私は`~/.claude/CLAUDE.md`（グローバルルール）に以下を記載した。

```markdown
## チーム編成ルール

- Agent Teamsでチームを編成する場合、必ず
  **デビルズアドボケイト（批判的レビュアー）**を1名含めること
- デビルズアドボケイトの役割: 全成果物を批判的視点でレビューし、
  見落としているリスク・前提条件の誤り・実行可能性の問題・
  コスト試算の甘さを指摘する
- 他のエージェントのタスク完了後にレビューを開始する
- レビュー結果は記録・保存する
```

これにより、どのプロジェクトでClaude Codeを起動しても、チーム編成時にDAが自動的に考慮される。

## まとめ

- **DAを入れないAIチームは「全員イエスマン」になる**。AIエージェントは与えられたタスクを遂行するが、自発的に批判はしない
- **マルチラウンドレビューで品質が劇的に改善する**。R1で問題を検出し、R2で反映率を追跡し、R3で実行可能性を判定する。私のケースではR2時点で高重要度9件あった問題がR3で1件に減少した
- **コストは追加エージェント1つ分だけ**。チームに1台DAを追加するだけで、セキュリティバグ、工数の過小見積もり、ドキュメント矛盾といった問題を早期に発見できる
- **CLAUDE.mdに「DA必須」ルールを書くことで定着する**。仕組み化しないと、忙しい時ほどDAを省略してしまう

AIがコードを書く時代、その品質を誰が担保するのか。答えの一つは、AIチームの中に「反対意見を述べる係」を置くことだ。

## 参考資料

- [Qodo「State of AI code quality」レポート](https://www.qodo.ai/reports/state-of-ai-code-quality/) -- AIレビュー統合で品質改善81%（なし55%）、600名超の開発者調査（2025年）
- [Anthropic Agent Teams公式ドキュメント](https://code.claude.com/docs/en/agent-teams) -- Claude Code Agent Teamsの機能・設定・ユースケース
- [richiethomas/claude-devils-advocate（GitHub）](https://github.com/richiethomas/claude-devils-advocate) -- Claude Code用DAスラッシュコマンド（PR前の多ラウンドレビュー）
- [Google DeepMind「Devil's Advocate: Anticipatory Reflection for LLM Agents」](https://arxiv.org/abs/2405.16334) -- LLMエージェントの事前反省手法（EMNLP 2024 Findings採録）
- [DORA 2025 State of AI-assisted Software Development](https://dora.dev/research/2025/dora-report/) -- AI採用率90%、ただし組織レベルのデリバリー指標は横ばい

---
<!-- メタ情報（公開時に削除） -->
- リサーチノート: [[research-devils-advocate-ai]]
- DA レビュー: 済（数値不一致修正、出典URL追加、DORA数値削除）
- 配信先: Zenn
- 公開日: 未定
- リライト履歴: なし
