---
title: "1人法人の情報基盤設計 -- BigQuery + Discord + Obsidianで何ができるか"
emoji: "🧭"
type: "idea"
topics: ["bigquery", "discord", "obsidian", "gcp", "solo"]
published: true
publication_name: "correlate_dev"
published_at: "2026-02-17 08:00"
slug: "solo-corp-info-platform"
---

## 1人法人の情報管理は「何を使うか」より「なぜそれを選ぶか」

合同会社を1人で回していると、経営者・エンジニア・経理・営業のすべてを自分でこなすことになります。複数の役割を行き来するなかで、情報管理の問題は避けて通れません。案件の進捗、売上の推移、工数の記録、判断の履歴——これらが散在していると、毎回「どこに何があったか」を探すところから始まることに。

「NotionとGoogleスプレッドシートでなんとかならないか？」

最初はそう考えていました。実際、しばらくはそれで回っていた時期もある。しかしデータが増えるにつれ、Notionのデータベースが20,000行を超え、複雑なリレーションやロールアップを多用しているページで動作が重くなり、スプレッドシートの関数では複雑な集計に限界が見えてきた。

ツールの選び直しを迫られたとき、「何を使うか」の前に「なぜそれを選ぶか」を考える必要があった。ツールは入れ替えが効くけれど、設計思想は簡単には変えられない。この記事では、BigQuery + Discord + Obsidianという構成に至った「Why」を共有します。

具体的なアーキテクチャや構築手順は「[1人法人のGCP業務基盤を月額5ドル以下で構築した話](https://zenn.dev/correlate_dev/articles/solo-corp-gcp)」で解説済みです。本記事はその前段にある設計思想の話。

## 情報基盤に求めた3つの要件

ツール選定に入る前に、そもそも情報基盤に何を求めているのかを整理しました。行き着いたのは3つの要件。

「集める」— 日々の作業ログ、判断の記録、エラー対処の履歴。散在する情報を1箇所に集約したい。入力の摩擦が小さいこと。思いついた瞬間に書けなければ、情報は失われてしまう。

「蓄める」— 集めた情報を構造化して、検索・集計・分析ができる形で保存したい。半年後に「あのときどう判断したか」「あの案件の利益率はいくらだったか」をSQLで引き出せること。これが経営判断の土台になります。

「見る」— 蓄めたデータを、いつでもどこでも確認できるようにしたい。朝起きてスマホを開けば、今日やるべきことがわかる。出先でも経営状況を一目で把握できる。そういう体験を目指しました。

この3層モデルに当てはめると、各ツールの役割が自然に決まっていく。

## なぜBigQueryなのか -- 「蓄める」の設計思想

「1人法人のデータ量でBigQueryは大げさでは？」

もっともな疑問でしょう。実際、私のBigQueryには18テーブルが稼働していますが、全データを合わせても数MBの世界。BigQueryが本領を発揮するペタバイト級のデータとは程遠い規模です。

それでもBigQueryを選んだ理由は5つ。

### 無料枠が「十分すぎる」という安心感

BigQueryのAlways Free枠は毎月10GBのストレージと1TBのクエリ処理。1人法人のデータ量で、この枠を使い切ることはまずないでしょう。「コストを気にしながらクエリを打つ」というストレスがゼロになるのは、日常的にデータを見る習慣をつけるうえで大きかった。

NotionやAirtableにも無料プランはありますが、Airtableは1ベースあたり1,000レコード、Notionは大量データでのパフォーマンス劣化という制約がつきまとう。BigQueryにはその種の上限がありません。

### SQLという「共通言語」の価値

独自のクエリ言語やフィルター機能ではなく、標準SQLでデータにアクセスできる点が決定的でした。SQLは学習コストが転用可能な汎用スキル。Notionのフィルターやフォーミュラの書き方を覚えても、それはNotion以外では使えません。

BigQueryで書いたSQLの知識は、PostgreSQLでもMySQLでもSnowflakeでも活きる。ツールに縛られないスキルを蓄積できる選択を重視しました。

### サーバーレスという「放置できる」アーキテクチャ

1人法人がインフラ管理に時間を使うのは本末転倒でしょう。BigQueryはフルマネージドなので、インデックスのチューニングもサーバーの監視もバックアップの設定も不要。テーブルを作ってデータを入れ、SQLを書く。それだけで分析基盤が動きます。

PostgreSQLやMySQLを自前で運用する選択肢もありましたが、「夜中にDBが落ちたら誰が対応するのか」を考えると、サーバーレスは1人法人にとって唯一の合理的な選択でした。

### Notionの限界を実感した経験

Notionは素晴らしいツールですが、「データベース」としての限界は確かに存在する。私が直面したのは以下の問題。

- 20,000行を超え、複雑なリレーションを多用すると読み込みが遅くなる
- 複数テーブルをまたいだ集計（JOINに相当する操作）が困難
- リレーション + ロールアップの組み合わせが複雑になると挙動が不安定

Notionの本質はドキュメントツールであり、データウェアハウスではない。その境界を認識してからは、「入力はObsidian、分析はBigQuery」と役割を分けることで、それぞれの強みを活かせるようになった。

### スケールの天井がないという保険

今は数MBでも、1年後、3年後にはデータ量がどうなるかわからない。案件が増えれば工数ログは膨らむし、外部API連携を増やせばデータソースも増える。そのときに「基盤を作り直す」のは避けたかったのです。

BigQueryなら、テーブルを追加するだけ。今のところ18テーブルですが、50テーブルになっても100テーブルになっても、同じ基盤で運用し続けられます。この安心感は意外に大きいものでした。

## なぜDiscordなのか -- 「見る」の設計思想

BigQueryで「蓄める」基盤が決まったら、次は「見る」仕組みが必要になる。1人法人に「社内ポータル」は要らないけれど、「ダッシュボード」は要る。この微妙なニーズを満たすのがDiscordでした。

### Slack vs Discord: 無料枠の差

最初に候補に挙がったのはSlack。しかしSlackの無料プランは90日を超えたメッセージが検索できなくなる制限があります。1人法人の情報基盤として使うなら、過去の通知やレポートを遡って確認できることが必須条件。Discordにはこの制限がありません。

もちろん、Slackの有料プラン（Pro）を使えば解決する問題ではある。ただ月額$8.75/ユーザーを1人法人が払う合理性があるかと問われると、疑問が残りました。

### Botが「自分専用の情報アシスタント」になる

DiscordのBot APIは非常に充実しています。Webhook、スラッシュコマンド、ボタンUI、Embed（色分けされたカード表示）。これらを組み合わせると、テキストチャットの枠を超えた情報表示が可能になる。

現在稼働中の朝会Botは、毎朝7時に6つのデータソースから情報を集め、カレンダー予定・アラート・KPIサマリー・タスク進捗・案件状況を色分けカードで配信してくれます。スマホでDiscordを開くだけで、今日やるべきことが一目でわかる。

「社員はいないけど、Botが秘書代わりになっている」——これは冗談ではなく、実際の運用実感です。

### スマホからアクセスできる日常

Looker StudioやGrafanaでダッシュボードを構築する選択肢もありましたが、「わざわざブラウザでURLを開く」という一手間が運用定着の妨げになります。Discordアプリは常にスマホに入っている。通知が来たらタップするだけ。この動線の短さが、データを「見る」習慣を定着させてくれました。

経営者が自社の数字を毎日見るのは当然のこと。でも1人法人だと、誰かに報告する義務がないから、ついサボってしまう。Botが毎朝レポートを届けてくれる仕組みは、その怠惰への対抗手段。想像以上に効果的でした。

## なぜObsidianなのか -- 「集める」の設計思想

「蓄める」「見る」が決まれば、最後は「集める」。情報を「集める」ツールに求めたのは、入力の速さと蓄積データの安全性。その両方を満たすのがObsidianでした。

### データのオーナーシップ問題

NotionやConfluenceはクラウドサービスであり、データはサービス提供者のサーバーに保存される。実用上は問題ないケースがほとんどでしょう。ただ、1人法人の全ナレッジを1つのSaaSに預ける判断にはためらいがあった。

Obsidianはローカルファイル（Markdown）ベース。データのオーナーシップが完全に自分にある。SaaSが値上げしても、サービス終了しても、データはただのテキストファイルとして手元に残り続けます。

### Markdownの移行性

「5年後に別のツールに移行したい」となったとき、Notionからのエクスポートは手間がかかる。一方、Markdownファイルはどのツールでも読めます。Obsidianから別のPKMツールに移行するのも、単純にフォルダをコピーするだけ。

ロックインされないことは、長期的な情報基盤にとって見過ごせない要件でしょう。

### AIエージェントとの親和性

ローカルのMarkdownファイルであるがゆえに、Claude CodeやCursorなどのAIエージェントからVault全体にアクセス可能。セッションログ、エラー記録、ナレッジベース——すべてのファイルをコンテキストとして活用できます。

現在、Obsidianの25以上のディレクトリにわたるデータを、Claude Codeのセッション管理やコンテンツパイプラインで日常的に参照しています。SaaSのAPIを叩かずにローカルファイルを直接読めるこの構造は、AI時代の情報基盤として理にかなっている。

### 「書く → 構造化 → 分析」のフロー

Obsidianの役割は「入力」への特化。素早くメモを取り、後で構造化する。分析はBigQueryに任せる。この役割分担こそが重要でした。

1つのツールに全機能を求めると、どの機能も中途半端になりがちでしょう。Obsidianは「書くこと」に最適化されたツールであり、それ以上を求めない。この割り切りが、3ツール統合の設計思想の根幹にあります。

## 3ツールの統合で何が実現したか

3つのツールが連携すると、単体では不可能だった体験が生まれる。

```
Obsidian（集める）→ BigQuery（蓄める）→ Discord（見る）
```

具体的にはこんなことが日常になりました。

朝会Botが今日やるべきことを教えてくれる。BigQueryに蓄積された案件データ・工数データ・カレンダー情報をもとに、Discord上で毎朝ブリーフィングが届く。「次に何をすべきか」で悩む時間がゼロに。

月次の売上推移をDiscordで確認できる。freee APIから同期された請求書データがBigQueryに蓄積され、Discordのスラッシュコマンドで月次推移を即座に表示。わざわざfreeeにログインする必要がなくなりました。

案件の利益率をリアルタイムで把握できる。工数ログ（Obsidian経由）と請求データ（freee経由）をBigQueryでJOINし、案件ごとの粗利率を自動算出。FIRE基準の粗利率35%を下回る案件には自動でアラートが飛ぶ仕組み。

セッションログが経営データに変わる。Obsidianに書いたセッション記録が、日次同期パイプラインでBigQueryに取り込まれ、工数分析や稼働時間の可視化に活用される。「記録すること」が「分析すること」に直結している。

アーキテクチャの詳細や各エンドポイントの構成は「[1人法人のGCP業務基盤を月額5ドル以下で構築した話](https://zenn.dev/correlate_dev/articles/solo-corp-gcp)」を参照してください。

## 月額コストの実績

理想論だけでは説得力がないので、実際のコストを公開します。2026年2月時点の月額実績。

| サービス | 月額 | 備考 |
|:--|:--|:--|
| BigQuery | $0 | 無料枠内（ストレージ数MB、クエリ数GB/月） |
| Cloud Run | $2〜5 | Discord Bot常駐のためmin-instances=1（常駐させない構成なら無料枠内も可能） |
| Cloud Scheduler | $0.30 | 日次バッチ3ジョブ |
| Artifact Registry | $0〜1 | Dockerイメージ保管 |
| Secret Manager | $0 | 少量シークレット管理 |
| Obsidian | $0 | ローカルアプリ（Sync未使用） |
| Discord | $0 | 無料プラン |
| **合計** | **$2〜6程度** | |

「無料」ではなく「無料枠内」という表現が正確。GCPにはクレジットカードを登録しており、無料枠を超えれば課金されます。ただし1人法人のデータ量では、無料枠を超える見込みは当面ない。

Cloud Runは最小インスタンス数（min-instances）を0にすれば無料枠内で運用可能ですが、Discord Botの応答速度を優先してmin-instances=1で常駐させているため、月額$2-5程度のコストが発生しています。

同等の機能をSaaSの組み合わせで実現しようとすると、Notion（チーム）+ Slack（Pro）+ 何らかの自動化ツールで月額$30〜50は見込まれるでしょう。もちろん、構築にかかる時間は無料ではないので、単純なコスト比較で優劣をつけるべきではありません。

## この設計のトレードオフ

良い面だけ書くのはフェアではない。この構成の弱点も正直に記しておきます。

BigQueryのレイテンシとして、クエリ実行に数秒かかる。リアルタイム性が求められるダッシュボードには不向き。ただし朝会Botや日次レポートなど、数秒の遅延が問題にならないユースケースでは十分実用的でした。

Obsidianのモバイル体験。デスクトップでは快適ですが、スマホでの入力は正直イマイチ。出先でのメモはiOSのメモアプリに書き、帰宅後にObsidianに転記するワークフローで対処中。

Discordのセキュリティ。Discordは本来ゲーマー向けのプラットフォーム。機密性の高い経営情報を流す場としては、エンタープライズ向けツールに比べるとセキュリティ面で見劣りする部分は否めません。サーバーを非公開にし、Bot以外のアクセスを制限する運用でカバーしているものの、この点は各自のリスク判断に委ねるべきでしょう。

「1人で全部やる」リスク。この基盤を構築・運用できるのは、コードを書ける人間に限られる。構築に100時間以上の投資が必要であり、ノーコードツールで同等の体験を得たほうが効率的なケースも多いはず。「自分で作りたい」というモチベーションがない場合、素直にNotionやkintoneを選ぶほうが賢明かもしれません。

## まとめ: 1人でも「仕組み」は作れる

1人法人の情報基盤設計で考えたのは、テクノロジーの選択そのものよりも「なぜそれを選ぶのか」という思想の部分でした。

- BigQuery — 無料枠・SQL・サーバーレスという3つの理由で「蓄める」を担当
- Discord — 無制限の履歴・強力なBot API・スマホアクセスで「見る」を担当
- Obsidian — ローカルファイル・Markdown・AI親和性で「集める」を担当

「集める・蓄める・見る」の3層に分けて考えることで、各ツールの責務が明確になり、将来的な入れ替えも容易になる。Obsidianが合わなければ別のPKMに、Discordが合わなければLINEやSlackに差し替えても、BigQueryの分析基盤はそのまま活きます。

小さく始めて、必要に応じて拡張する。月額$5以下で、エンタープライズが使うのと同じ分析エンジンを手に入れる。1人法人だからこそできる、身軽な情報基盤設計の話でした。

## 参考資料

https://cloud.google.com/bigquery/docs/introduction?hl=ja

https://cloud.google.com/bigquery/pricing

https://cloud.google.com/free

https://cloud.google.com/run/pricing

https://discordpy.readthedocs.io/

https://obsidian.md/

https://zenn.dev/igz0/articles/8888bbc309f3d6

https://gihyo.jp/article/2025/05/obsidian-05

https://scr.marketing-wizard.biz/notion/notion-db-performance-test

https://auto-worker.com/blog/?p=6174
