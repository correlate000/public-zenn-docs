name: Sync Articles to BigQuery

on:
  push:
    branches: [main]
    paths:
      - 'articles/**'
  workflow_dispatch:  # 手動実行

jobs:
  sync:
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write  # OIDC認証に必要
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        id: auth
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: projects/62187303601/locations/global/workloadIdentityPools/github-pool/providers/github-provider
          service_account: scheduler-sa@correlate-workspace.iam.gserviceaccount.com
          token_format: id_token
          id_token_audience: https://correlate-api-62187303601.asia-northeast1.run.app
          id_token_include_email: true

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install pyyaml

      - name: Parse articles and sync to BigQuery
        env:
          SYNC_API_URL: ${{ secrets.SYNC_API_URL }}
          ID_TOKEN: ${{ steps.auth.outputs.id_token }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import json
          import re
          import urllib.request
          import yaml
          from pathlib import Path

          ARTICLES_DIR = Path("articles")
          PLATFORM = "zenn"
          ZENN_BASE_URL = "https://zenn.dev/correlate000/articles"
          API_URL = os.environ.get("SYNC_API_URL", "")
          ID_TOKEN = os.environ.get("ID_TOKEN", "")

          def parse_frontmatter(content):
              """YAML frontmatterを抽出"""
              match = re.match(r'^---\s*\n(.*?)\n---\s*\n', content, re.DOTALL)
              if not match:
                  return {}, content
              try:
                  meta = yaml.safe_load(match.group(1))
                  body = content[match.end():]
                  return meta or {}, body
              except yaml.YAMLError:
                  return {}, content

          def count_words(body):
              """日本語＋英語の文字数（マークダウン記法除去後）"""
              cleaned = re.sub(r'```.*?```', '', body, flags=re.DOTALL)
              cleaned = re.sub(r'`[^`]+`', '', cleaned)
              cleaned = re.sub(r'[#*\[\]()>!|_~-]', '', cleaned)
              cleaned = re.sub(r'\s+', '', cleaned)
              return len(cleaned)

          def count_code_examples(body):
              """コードブロック（```...```）の数を数える"""
              return len(re.findall(r'```', body)) // 2

          articles = []
          for md_file in sorted(ARTICLES_DIR.glob("*.md")):
              content = md_file.read_text(encoding="utf-8")
              meta, body = parse_frontmatter(content)

              slug = md_file.stem
              title = meta.get("title", slug)
              article_type = meta.get("type", "tech")
              topics = meta.get("topics", [])
              published = meta.get("published", False)
              published_at_raw = meta.get("published_at", None)

              status = "published" if published else "draft"
              source_tags = ",".join(topics) if isinstance(topics, list) else str(topics)
              published_url = f"{ZENN_BASE_URL}/{slug}" if published else ""

              article = {
                  "id": f"zenn-{slug}",
                  "title": title,
                  "article_type": article_type,
                  "status": status,
                  "source_content_id": slug,
                  "source_tags": source_tags,
                  "published_url": published_url,
                  "word_count": count_words(body),
                  "code_example_count": count_code_examples(body),
                  "da_review_count": 0,
                  "da_feedback": "",
              }

              if published_at_raw:
                  article["published_at"] = str(published_at_raw)

              articles.append(article)

          print(f"Parsed {len(articles)} articles")
          for a in articles:
              print(f"  - {a['id']}: {a['title'][:40]}... ({a['status']}, {a['word_count']}字, code:{a['code_example_count']})")

          if not API_URL:
              print("SYNC_API_URL not set. Dry run only.")
          else:
              payload = json.dumps({"articles": articles, "platform": PLATFORM}).encode("utf-8")
              headers = {"Content-Type": "application/json"}
              if ID_TOKEN:
                  headers["Authorization"] = f"Bearer {ID_TOKEN}"
                  print("Using authenticated request with ID token from Workload Identity Federation")
              else:
                  print("Warning: No ID token available, trying unauthenticated")

              req = urllib.request.Request(API_URL, data=payload, headers=headers, method="POST")
              try:
                  with urllib.request.urlopen(req, timeout=30) as resp:
                      result = json.loads(resp.read().decode("utf-8"))
                      print(f"Sync result: {json.dumps(result, ensure_ascii=False)}")
              except Exception as e:
                  print(f"Sync failed: {e}")
                  print("Warning: BigQuery sync failed but workflow continues")
          PYTHON_SCRIPT
